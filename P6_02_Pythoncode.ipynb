{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings for the Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-92ce8c576036>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"whitegrid\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m{\u001b[0m\u001b[0;34m\"xtick.major.size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ytick.major.size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "height, aspect = (8, 2)\n",
    "rc={'figure.figsize': (20, 18)}\n",
    "sns.set_style(\"whitegrid\",  {\"xtick.major.size\": 8, \"ytick.major.size\": 8, height: height, aspect: aspect})\n",
    "sns.set(font_scale=2, rc=rc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration phase EDA.\n",
    "## getting to know and understand the data numerically and visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import scipy.special as stat_special\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from scipy.cluster import hierarchy\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from patsy import dmatrices\n",
    "from functools import *\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from custom_mdls.functions_plots import plot_dendrogram, display_factorial_planes, display_parallel_coordinates, display_parallel_coordinates_centroids, display_scree_plot, display_circles, append_class\n",
    "from adjustText import adjust_text\n",
    "from sklearn.cluster import KMeans\n",
    "import yellowbrick.cluster as yellowbrick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the needed Data set for the first Analysis\n",
    "\n",
    "Here I upload the food security from the Fao data web platform for information about countries' nutrition and Crops live stocks. I also got information about life stock products produced by governments and others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_food_sicurity = pd.read_csv('./data/food_sicurity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_food_balance = pd.read_csv('./data/food_balance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices = pd.read_csv('./data/producer_prices.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator = pd.read_csv('./data/macro_indicator.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observing the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First and last five rows of Food Security shape and size of the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this dataFrame, there are 4866 rows organized by 15 columns**\n",
    "\n",
    "4 Of them are identified metadata data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifies\n",
    "df_food_sicurity.columns[df_food_sicurity.columns.str.endswith('Code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_food_sicurity.columns[df_food_sicurity.columns.str.endswith('Code')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The columns and their observations**\n",
    "\n",
    "The domain is what the data set values are describing, with the countries as areas.\n",
    "\n",
    "The Element here is related to the actual observation Column called Value. \n",
    "\n",
    "Item is the type of observation but also contains unit or aggregation information. Example Value of food imports in total merchandise exports (percent) (3-year average) and Minimum dietary energy requirement (kcal/cap/day) one is an aggregation average by an amount of year, and the other is a minimum of a unit.\n",
    "\n",
    "A three-year column aggregated from 2017-to 2019 and a not aggregate one from 2018.\n",
    "\n",
    "Every single Value is based on his unit as it is visible in the Unit column, seven different ones\n",
    "\n",
    "The flag columns and notes are also a kind of metadata that may not be very important for our Analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elements available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_food_sicurity.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.Element.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Items available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_food_sicurity.Item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.Item.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Units available** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.Unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_food_sicurity.Unit.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Summary**\n",
    "\n",
    "It is one of the essential data frames here. \n",
    "This df_food_sicurity will give information about how many people have access to nutrients, health, Political state, and even how industrialized they could be with Rail lines density (total route in km per 100 square km of land area)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First and last five rows of Food Balance shape and size of the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this dataFrame, there are 82781 rows organized by 14 columns**\n",
    "\n",
    "4 Of them are identified metadata data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifies\n",
    "df_food_balance.columns[df_food_balance.columns.str.endswith('Code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_food_balance.columns[df_food_balance.columns.str.endswith('Code')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The columns and their observations**\n",
    "\n",
    "The domain is what the data set values describe, with the countries as areas.\n",
    "The Element here is related to the Items, for example, Element Total Population - Both sexes to Item. It explains how they are aggregated and what they contain, even for some units like Food supply (kcal/capita/day). \n",
    "\n",
    "Item is the type of observation such as Animal Products, Eggs, and Poultry Meat.\n",
    "\n",
    "There are two years, 2018 and 2019.\n",
    "\n",
    "Every single Value is based on his unit, as it is visible in the Unit column. Some of them are g/capita/day, kg.\n",
    "\n",
    "The flag columns and notes are also metadata that may not be very important for our Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elements available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_food_balance.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.Element.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Items available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_food_balance.Item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.Item.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Units available** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.Unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_food_balance.Unit.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "This data frame df_food_balance Is crucial for the Analysis to come only Element Total Population. Both sexes would give vital information about countries that we will consider and nutrition Elements like Food supply (kcal/capita/day) and Protein supply quantity (g/capita/day) which will clarify how to feed a county's population it is a given year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First and last five rows of Macro Indicator shape and size of the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this dataFrame, there are 25144 rows organized by 15 columns**\n",
    "\n",
    "4 Of them are identified metadata data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifies\n",
    "df_macro_indicator.columns[df_macro_indicator.columns.str.endswith('Code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_macro_indicator.columns[df_macro_indicator.columns.str.endswith('Code')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The columns and their observations**\n",
    "\n",
    "Item is the type of observation that indicates the Value or aggregation of some economic indicators like Gross Domestic Product \"GDP.\" Agriculture, Manufacture, Forestry, and Fishing are some of the item types of products considered here. \n",
    "\n",
    "The domain is what the data set values describe, with the countries as areas.\n",
    "\n",
    "The Element is also related to the Items. It explains their aggregation, for example, 2015, Rations, Anual, even for some units of Local currency and $ dollar.\n",
    "\n",
    "A range from 2018-to 2019.\n",
    "\n",
    "Every single Value is based on his unit as it is visible in the Unit column.\n",
    "\n",
    "The flag columns and notes are also a kind of metadata that may not be very important for our Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elements available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_macro_indicator.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.Element.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Items available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_macro_indicator.Item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.Item.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Units available**\n",
    "\n",
    "Some values like nan might not be relevant and can be removed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.Unit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_macro_indicator.Unit.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "df_macro_indicator data frame has a significant Item here as one of the major economic indicators, \"GDP\" for a country that will be very useful for future Analysis.\n",
    "\n",
    "Value Added (Total Manufacturing), Value Added (Agriculture), Gross Output (Agriculture), Gross Output (Agriculture, Forestry, and Fishing)\n",
    "It can also help to understand how industrial and economic a country is compared to others. This can affect where the company product has more competition and more financial stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First and last five rows of Food Prices shape and size of the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In this dataFrame, there are 4866 rows organized by 15 columns**\n",
    "\n",
    "4 Of them are identified metadata data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identifies\n",
    "df_producer_prices.columns[df_producer_prices.columns.str.endswith('Code')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_producer_prices.columns[df_producer_prices.columns.str.endswith('Code')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The columns and their observations**\n",
    "\n",
    "The domain is what the data set values describe, with the countries as areas.\n",
    "The Element here is related to the Items. It explains how they are aggregated like the Producer Price Index (2014-2016 = 100), even for some units USD/tonne.\n",
    "\n",
    "Item is the type of observation. Most of them are poultry products, meat, or eggs, and some are the weight of livening animals.\n",
    "A three-year column aggregated from 2017-to 2019 and a not aggregate one from 2018.\n",
    "\n",
    "Every single Value is based on his unit, as it is visible in the Unit column.\n",
    "\n",
    "The flag columns and notes are also a kind of metadata that may not be very important for our Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elements available**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_producer_prices.Element.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.Element.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Items available**\n",
    "\n",
    "Some values like \"Eggplants (aubergines)\" and \"other\" might not be relevant here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_producer_prices.Item.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.Item.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Units available**\n",
    "\n",
    "Some values like nan might not be relevant and can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_producer_prices.Unit.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.Unit.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "The df_producer_prices data frame contains many relevant pieces of information that will help further analyze a product's production in a different country and liven animals and their weights, significantly eggs as products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values.\n",
    "\n",
    "**Let us closely look at our data frames here.** \n",
    "\n",
    "Identify which columns contain missing values, and try to understand if these can be recovered with any methodology, like mean imputation, or removed entirely, but only after understanding its consequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food Security data set information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Information**\n",
    "\n",
    "As the first check, I use the information method to understand what kind of observation data structure is present in each column.\n",
    "\n",
    "We can see here RangeIndex: 4866, the number of rows, the total 15 columns and their names, the interesting column Non-Null Count, which is the amount not counted as null; and finally, Dtype, the type of data structure.\n",
    "\n",
    "There is no null value from the column index 0 to 10 because they all have the same total amount of row 4866.\n",
    "\n",
    "The most prevalent type of data structure here is the object that can be string values or worlds fallow by int64, which indicates a discrete numerical value. The last Dtype is a float64 that can describe continuous numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying and resolving null values**\n",
    "\n",
    "For clarity, let's compute the total of every column's null values.\n",
    "There are only 2 Columns that have null values here Value and Note. Note most probably because, as already mentioned in the Observation section, metadata is not relevant to our Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity[df_food_sicurity.Value.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justifying removal of missing values**\n",
    "\n",
    "Thankfully, the flag and flag description hint at why these observations are not present, describing them as Not reported or data unavailable.\n",
    "\n",
    "And Only now can I conclude that I can remove these rows and that the metadata information in Flag, Flag description, and Note are not needed anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity[(df_food_sicurity.Flag == 'NR') & (df_food_sicurity.Flag == 'NR')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.dropna(subset=['Value'], inplace=True)\n",
    "df_food_sicurity.drop(columns=['Flag', 'Flag Description', 'Note'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note => Add percentage of deleted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "They were a total of 514 null values confirmed by the flag metadata; at this point, these metadata are no longer necessary and are removed from the data frame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food Balance data set information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Information**\n",
    "\n",
    "As a first check, I used the information method to understand the kind of observation data structure in each column.\n",
    "\n",
    "We can see here RangeIndex: 82781, the number of rows, a total of 15 columns and their names, the interesting column Non-Null Count, which is the amount not counted as null, and finally, Dtype, the type of data structure.\n",
    "\n",
    "From the column index 0 to 10, there is no null value because they all have the same total amount of row 82781.\n",
    "\n",
    "The most prevalent type of data structure here is an object that can be string values or words fallow by int64, indicating a discrete numerical value. The last Dtype is a float64 that can describe continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying and resolving null values**\n",
    "\n",
    "For clarity, let's compute the total of every column's null values.\n",
    "There is only 1 Column that has null values here, and this is Value. I will find out why metadata like Flag and Flag Description is irrelevant for our Analysis on subsequent checks, as already mentioned in the Observation section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance[df_food_balance.Value.isnull()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justifying removal of missing values**\n",
    "\n",
    "This time the flag and flag description doesn't hint as to why these observations are absent; describing them as aggregated may include official or semi-official.\n",
    "\n",
    "And Only now can I conclude that this row above from the Area China can be removed and that the metadata information in Flag, Flag description, and Note are not needed anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance[(df_food_balance.Flag == 'A') & (df_food_balance.Area == 'China')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing china from each data frames\n",
    "#df_food_balance = df_food_balance[df_food_balance['Area Code (FAO)'] != 351]\n",
    "#df_food_sicurity = df_food_sicurity[df_food_sicurity['Area Code (FAO)'] != 351]\n",
    "#df_macro_indicator = df_macro_indicator[df_macro_indicator['Area Code (FAO)'] != 351]\n",
    "#df_producer_prices = df_producer_prices[df_producer_prices['Area Code (FAO)'] != 351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.dropna(subset=['Value'], inplace=True)\n",
    "df_food_balance.drop(columns=['Flag', 'Flag Description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclution**\n",
    "\n",
    "The flag metadata confirmed the total of 514 null values; at this point, these metadata are no longer necessary and are removed from the data frame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro data set information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Information**\n",
    "\n",
    "As a first check, I use the information method to understand the kind of observations and data structure in each column.\n",
    "\n",
    "We can see here RangeIndex: 82781, the number of rows, a total of 15 columns and their names, the interesting column Non-Null Count, which is the amount not counted as null, and finally, Dtype, the type of data structure.\n",
    "\n",
    "From the column index 0 to 10, there is no null value because they all have the same total amount of row 82781.\n",
    "\n",
    "The most prevalent type of data structure here is an object that can be string values or words fallow by int64, indicated to be a discrete numerical value. The last Dtype is a float64 that can describe continuous values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying and resolving null values**\n",
    "\n",
    "For clarity, let's compute the total of every column's null values.\n",
    "There is only 1 Column that has null values; here, this is Unit. I will find out why, on the subsequent checks, as already mentioned in the Observation section, metadata like Flag and Flag Description need to be more relevant for our Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator[df_macro_indicator.Unit.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justifying removal of missing values**\n",
    "\n",
    "This time the flag and flag description doesn't give us a hint as to why these observations are absent, describing them as Calculated data.\n",
    "\n",
    "But only now can I conclude that no row can be removed and that the metadata information in Flag, Flag description, and Note are not needed anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator[(df_macro_indicator.Flag == 'Fc')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.dropna(subset=['Value'], inplace=True)\n",
    "df_macro_indicator.drop(columns=['Flag', 'Flag Description', 'Note'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_macro_indicator.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclution**\n",
    "\n",
    "The were a total of 0 null values; instead, there is Unit, and the flag metadata does not confirm them; at this point, these metadata are no longer necessary and are removed from the data frame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Producer Prices data set information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Information**\n",
    "\n",
    "As a first check, I used the information method to understand the kind of observation data structure in each column.\n",
    "\n",
    "We can see here RangeIndex: 7769, the number of rows, a total of 16 columns and their names, the interesting column Non-Null Count, which is the amount not counted as null, and finally, Dtype, the type of data structure.\n",
    "\n",
    "From the column index 0 to 11, there is no null value because they all have the same total amount of row 7769; this time, the noted columns are Unit and Flag.\n",
    "\n",
    "The most prevalent type of data structure here is an object that can be string values or words fallow by int64, which indicates a discrete numerical value. The last Dtype is a float64 that can describe continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identifying and resolving null values**\n",
    "\n",
    "For clarity, let's compute the total of every column's null values.\n",
    "2 Columns have null values here at the Unit and Flag. I will find out why metadata like Flag and Flag Description are irrelevant for our Analysis on the subsequent checks, as already mentioned in the Observation section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices[df_producer_prices.Unit.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices[df_producer_prices.Flag.isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Justifying removal of missing values**\n",
    "\n",
    "This time the flag and flag description doesn't hint as to why these observations are not present, describing them as Calculated data.\n",
    "\n",
    "But only now can I conclude that no row can be removed and that the metadata information in the Flag description is not needed anymore!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.dropna(subset=['Value'], inplace=True)\n",
    "df_producer_prices.drop(columns=['Flag', 'Flag Description'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_producer_prices.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclution**\n",
    "\n",
    "The were a total of 0 null values; instead, there is Unit, Flag, and Description and they are not confirmed by the flag metadata or Note also not present in the data set; at this point, these metadata are no longer necessary and are removed from the data frame!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize your values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identified and organized types on our data frames\n",
    "\n",
    "**From the last section, we got information about the data types present in our data frames; the most prevalent was an object.**\n",
    "\n",
    "From a Computer Science perspective, they are primarily strings, suggesting that this could be a definite type from a statistical viewpoint. Thankfully Pandas help us to create this kind of type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of this hint mentioned, I went ahead in creating a categorical converter function that I use to convert all objects types in the dataframes by before identifying the columns that are objects, then converting to a category, then check the unit column, and trying to convert it to an ordinal category type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertToCategorical(df):\n",
    "    objects = list(map(lambda x: x == 'object', df.dtypes))\n",
    "    categoricals = df[df.columns[objects]].astype('category')\n",
    "    order = CategoricalDtype(categoricals.Unit.unique().dropna(), ordered=True)\n",
    "    categoricals.Unit.astype(order)\n",
    "    return categoricals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining the dataType predictor function**\n",
    "\n",
    "I use this function to create a more detailed data type table separating integer to float numbers as descript, and continuing this will be handy in future Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataType(df):\n",
    "    type = pd.DataFrame(df.dtypes, columns=['data_structure'])\n",
    "    conditions = [((df.dtypes == 'category') | (df.dtypes == 'object')), (df.dtypes == 'int64'), (df.dtypes == 'float64')]\n",
    "    type['type'] = np.select(conditions,  ['categorical', 'num discrete', 'num continue'])\n",
    "    return type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Food balance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType(df_food_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conveting Food sicurity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_food_sicurity[convertToCategorical(df_food_sicurity).columns] = convertToCategorical(df_food_sicurity)\n",
    "dataType(df_food_sicurity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Macro indicators**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType(df_macro_indicator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting Poducer prices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_producer_prices[convertToCategorical(df_producer_prices).columns] = convertToCategorical(df_producer_prices)\n",
    "dataType(df_producer_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This section gave me more information about the columns' data types in all data frames. I used a function to convert the objects to a category for better-identifying strings as categorical data. It will be handy to determine how to visualize them, for example, a contingent table and then using a Categ plot with seaborn. I also got more info about the numerical values as discrete or continue and the Unit column that can be an ordered category.\n",
    "\n",
    "One significant finding in this section is the unseal value of food_sicurity as categorical when all the other data frames are numerical.\n",
    "This information will be used to convert these categorical values to numerical then I will continue to the next section before merging all data frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the data sets with the needed columns and proper name\n",
    "\n",
    "I am creating a list of not need columns and a dictionary for renaming columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_columns = {'Area Code (FAO)': 'country_code', 'Area': 'country', 'Element Code': 'element_code', 'Element': 'element', 'Item Code': 'item_code',\n",
    "       'Item': 'item', 'Item Code (FAO)': 'item_code', 'Year': 'year', 'Unit': 'unit', 'Value': 'value'}\n",
    "\n",
    "rename_food_balance_columns = {'Area Code': 'country_code', 'Area': 'country', 'Element Code': 'element_code', 'Element': 'element', 'Item Code': 'item_code',\n",
    "       'Item': 'item', 'Unit': 'unit', 'Year': 'year', 'Value': 'value'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Renaming Columns.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance.rename(columns = rename_columns, inplace=True)\n",
    "df_food_sicurity.rename(columns = rename_columns, inplace=True)\n",
    "df_producer_prices.rename(columns = rename_columns, inplace=True)\n",
    "df_macro_indicator.rename(columns = rename_columns, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Removing China mainland.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_balance = df_food_balance[df_food_balance.country != 'China, mainland']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure that the values on security are float values**\n",
    "\n",
    "As already found from the categorized section, the food security value doesn't have a correct type, so here I am converting it to a numerical continue value that makes it easy for the following Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_food_sicurity.value = df_food_sicurity.value.str.extract('(\\d+)', expand=False).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mergin small data frames with large ones so i can use 2 data frames insteady of 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the shape of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this section, I will focus on finding the shape of the essential Items and Elements that could answer the company's business questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify relationships in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate any outliers in the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Difference in population between a previous year (elective) and the current year, expressed as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = df_food_balance[(df_food_balance.element == 'Total Population - Both sexes')]\n",
    "top_countries = criteria.sort_values(by='value', ascending=False)[:20].country.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_functions = {\n",
    "    'value':\n",
    "    ['sum', 'max', 'min']\n",
    "}\n",
    "var_name=['values', 'aggregations', 'years', 'elements', 'items']\n",
    "table_top_10 = df_food_balance[df_food_balance.country.isin(top_countries)].pivot_table(index= ['country'], columns=['year', 'element', 'item'],  aggfunc=agg_functions, fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_2018 = df_food_balance[(df_food_balance.element == 'Total Population - Both sexes') & (df_food_balance.year == 2018)].value\n",
    "pop_2019 = df_food_balance[(df_food_balance.element == 'Total Population - Both sexes') & (df_food_balance.year == 2019)].value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_2018 = pd.DataFrame(data=pop_2018.values, columns=[ '2018'])\n",
    "pop_2019 = pd.DataFrame(data=pop_2019.values, columns=[ '2019'])\n",
    "\n",
    "pop_2018['country'] = df_food_balance.country.unique()\n",
    "pop_2019['country'] = df_food_balance.country.unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country = pd.merge(pop_2018, pop_2019, on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country['pop_trend_%'] = ((df_country['2019'] - df_country['2018']) / df_country['2018']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country['pop_total'] =  df_country['2019'] + df_country['2018'] * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Too many countries**\n",
    "\n",
    "There are 180 countries, which is hard to visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country.country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This is only one quote from the 180 countries!**\n",
    "\n",
    "If we try to plot 45 countries, we can understand their distribution based on population trends, but it needs to be clarified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df_country[:45], x='country', y='pop_trend_%',height=10, aspect=4).set( title='populatio Grow in percentage')\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reducing amount of countries based on criteria**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our Analysis, we will only need the top 10 countries based on criteria or column value, in this case, pop_total.\n",
    "Here are our ten countries in a data frame: China, India, and the USA are the top 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_populated_countries = df_country.sort_values(by=['pop_total'], ascending=False)[:10].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_populated_countries =  pd.DataFrame(top_populated_countries)\n",
    "top_populated_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the top 10 most populated countries?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot( data= top_populated_countries, y= 'pop_total', x='country').set( title='Total top 10 population per capita')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "China has the highest population of all the countries, which is a difference of more than 205 thousand per 1000 citizens compared to India in second place on this top 10, the USA here is in Third place here, and Brazil is part of the top 5.\n",
    "Russia and Japan are the last ones. Even if Tokyo is one of the most densely populated countries in the world, the overall population is smaller than Indonesia, Pakistan, Nigeria, Bangladesh, and Russia, so our number is 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the top 10 populated countries in percentage?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_populated_countries = df_country.sort_values(by=['pop_trend_%'], ascending=False)[:10].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_populated_countries =  pd.DataFrame(top_populated_countries)\n",
    "top_populated_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot( data= top_populated_countries, x= 'pop_trend_%', y='country').set( title='population growth in percentage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our 10 top countries by population let us see how this population is growing!\n",
    "To our surprise, none of the top 10 countries per population make it to this new criteria pop_trend_% \"population growth in percentage.\"\n",
    "\n",
    "Another find here is that all countries in this list are from the African continent, with no European, Nord, or South American countries here.\n",
    "In the first place, there is Niger, fallow by Uganda and Angola, and this last one is currently in intense economic development, which can explain its population growth!\n",
    "\n",
    "Oman, the United Republic of Tanzania, and Gambia are the last Three on this criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population main indicators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[['pop_trend_%', 'pop_total']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Selection data set has 180 countries with a population trend in percentage mean of 1.21 percent and a total mean of more than 42 million.\n",
    "A minimum value of -2.69 population trend in percentage and a max of 160 million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Population trends in percentage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['pop_trend_%'] == df_country['pop_trend_%'].max()][['country', 'pop_trend_%' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['pop_trend_%'] == df_country['pop_trend_%'].median()][['country', 'pop_trend_%' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['pop_trend_%'] == df_country['pop_trend_%'].min()][['country', 'pop_trend_%' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pupulation total**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['pop_total'] == df_country['pop_total'].max()][['country', 'pop_total' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['pop_total'] == df_country['pop_total'].median()][['country', 'pop_total' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['pop_total'] == df_country['pop_total'].min()][['country', 'pop_total' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the main indicators here, we have different countries that hold the max, median, and min values:\n",
    "In this selection, we have China with the maximum value, Hungary represents the median, and the minimum is Saint Kitts, and Nevis is a tiny country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Proportion of animal proteins compared to the total amount of proteins available in the country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_supply_quantity_g_c_day = df_food_balance[df_food_balance.element == 'Protein supply quantity (g/capita/day)'].groupby('country')['value', 'country'].sum()\n",
    "food_supply_kcal_c_day = df_food_balance[df_food_balance.element == 'Food supply (kcal/capita/day)'].groupby('country')['value', 'country'].sum()\n",
    "food = df_food_balance[df_food_balance.element == 'Food'].groupby('country')['value', 'country'].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country = pd.merge(df_country, protein_supply_quantity_g_c_day, on=('country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country = pd.merge(df_country, food_supply_kcal_c_day, on=('country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country = pd.merge(df_country, food, on=('country'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country.rename(columns={'value_x':'protein_supply_quantity_g_c_day', 'value_y':'food_supply_kcal_c_day', 'value': 'food'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country['food_supply_kcal'] = df_country.food_supply_kcal_c_day * df_country['pop_total'] * 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country['food_supply_kgprotein'] = df_country.protein_supply_quantity_g_c_day / 1000 * df_country['pop_total'] * 365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country['food_supply_kg'] = df_country.food * 1000 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country['protein_percentage'] = df_country.food_supply_kgprotein / df_country.food_supply_kg * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_protein_percentage_countries = df_country.sort_values(by=['protein_percentage'], ascending=False)[:10].copy()\n",
    "top_protein_percentage_countries = pd.DataFrame(top_protein_percentage_countries)\n",
    "top_protein_percentage_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot( data= top_protein_percentage_countries, x= 'protein_percentage', y='country').set( title='Population High Protein in percentage')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the protein consumption per country, we get a different figure here!\n",
    "New countries like Papua New Guinea emerge as the leading protein consumer, followed by Mauritius, Corte D'ivorie, Grenade, Gabon, and Congo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protein main indicators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[['protein_percentage']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this selection, with all the 180 countries, we have a mean of 18% and a standard deviation of 4.67%. The minimal values here are above 10.47% with a Max of 30.49%. One-quarter of the percentage of protein is 14.15%, a third of 22.22%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Protein total**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['protein_percentage'] == df_country['protein_percentage'].max()][['country', 'protein_percentage' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['protein_percentage'] == df_country['protein_percentage'].median()][['country', 'protein_percentage' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['protein_percentage'] == df_country['protein_percentage'].min()][['country', 'protein_percentage' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Papua New Guinea holds the maximal percentage of protein, the median value here is from Iraq, and the minimum value is from Slovakia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Food availability in protein per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_food_supply_kgprotein_countries = df_country.sort_values(by=['food_supply_kgprotein'], ascending=False)[:10].copy()\n",
    "top_food_supply_kgprotein_countries =  pd.DataFrame(top_food_supply_kgprotein_countries)\n",
    "top_food_supply_kgprotein_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot( data= top_food_supply_kgprotein_countries, x= 'country', y='food_supply_kgprotein').set( title='Food availability in protein per capita.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the expected figure; these countries are highly or entirely industrialized, so as expected, they have a lot of protein supply. \n",
    "\n",
    "Because their population also influences this top 10 selection, we have China leading then the USA, India, Brazil, and Russian Federation.\n",
    "One extra good insight here is that wealth is not a predictor for protein supply in kg per capita."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Protein main indicators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[['food_supply_kgprotein']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The supply of protein per Kg here by countries has a mean of more than 2 million, and its standard deviation is more than 7,5 million. The min of about 3,5 million and a max of almost 9 million."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**food supply kg protein**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['food_supply_kgprotein'] == df_country['food_supply_kgprotein'].max()][['country', 'food_supply_kgprotein' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['food_supply_kgprotein'] == df_country['food_supply_kgprotein'].median()][['country', 'food_supply_kgprotein' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['food_supply_kgprotein'] == df_country['food_supply_kgprotein'].min()][['country', 'food_supply_kgprotein' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, on the selected countries' main indicators, we see China representing the maximal value, the median is New Zealand, and again the minimal is Saint Kitts and Nevis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then try by himself 2 graphs for the next 2 questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Food availability in calories per capita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_food_supply_kcal_countries = df_country.sort_values(by=['food_supply_kcal'], ascending=False)[:10].copy()\n",
    "top_food_supply_kcal_countries =  pd.DataFrame(top_food_supply_kcal_countries)\n",
    "top_food_supply_kcal_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot( data= top_food_supply_kcal_countries, x='country', y='food_supply_kcal').set( title='Food availability in calories per capita.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This figure confirms the relationship between population and food supply, once again, we have China as first in this selection, but this time India is before the USA, fallow by Brazil and Russian Federation.\n",
    "A more detailed analysis of key indicators like GDP, Industrialization level, and Economy orientation type would give us more insight to why countries like Germany, France and Japan are in the last places in this figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Food supply kcal main indicators!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[['food_supply_kcal']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This last country's selection has a mean food supply in kilo calories of 33 trillion, a standard deviation of 135 trillion. The minimum here is 54 billion and more than one quadrillion kcal of protein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**food supply kgcal main countries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['food_supply_kcal'] == df_country['food_supply_kcal'].max()][['country', 'food_supply_kcal' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['food_supply_kcal'] == df_country['food_supply_kcal'].median()][['country', 'food_supply_kcal' ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_country[df_country['food_supply_kcal'] == df_country['food_supply_kcal'].min()][['country', 'food_supply_kcal' ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the countries with the values of some of these indicators?\n",
    "Here again, we can see that China has the maximal value of food supply in kcal, Ghana has the median value, and Saint Kitts and Nevis, a very small country, have the minimal indicator value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "China is the country that most appears in these figures, having a vast population that requires and consumes a lot of food and protein to maintain its workforce and continue to grow economically.\n",
    "\n",
    "Another persistent country here is USA and India, Brazil, and Russian Federation, perhaps because of their population.\n",
    "\n",
    "Brazil, India, and Russia are part of the so call BRIC, a group of emergent strong economic countries that require a lot of food to keep growing.\n",
    "\n",
    "Germany and Japan are also present a few times more than other countries; they are economic powerhouses and have a significant amount of population that also food, especially protein.\n",
    "\n",
    "Worth to mention also is France, Mexico, Pakistan, and Indonesia are less present but are in some selections.\n",
    "\n",
    "From all the questions, we obtained ten countries with a total of 31 countries. They will be used in the next session of this Analysis, where we will apply more advanced algorithms that will reveal how this country is related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "studyCountries = pd.concat([top_populated_countries.country, top_protein_percentage_countries.country, top_food_supply_kgprotein_countries.country, top_food_supply_kcal_countries.country, top_protein_percentage_countries.country], ignore_index=True)\n",
    "\n",
    "studyCountries.sort_values(ascending=True, ignore_index=True, inplace=True)\n",
    "\n",
    "studyCountries = studyCountries.unique()\n",
    "studyCountries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) A dendrogram containing all the studied countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PESTLE Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the main perlst dataframe\n",
    "\n",
    "df_perstl = df_country[df_country.country.isin(studyCountries)][['country','pop_total', 'pop_trend_%', ]]\n",
    "df_perstl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a generic function to extract data from all slected study data frame.\n",
    "def mergeExtradata(df_to_study: DataFrame = pd.DataFrame(), df_perstl: DataFrame = pd.DataFrame(), df_selected_study: DataFrame = pd.DataFrame(), column: str = ''):\n",
    "    \n",
    "    column = str.lower(column).replace(', ', '_').replace(' ', '_')\n",
    "    df_selected_study = df_selected_study.groupby('country').value.sum().to_frame()\n",
    "    df_perstl = pd.merge(df_perstl, df_selected_study, on='country', how='left', suffixes=('_' + column) )\n",
    "    df_perstl.rename(columns={'value': 'value_' +column}, inplace=True)\n",
    "    df_perstl.fillna(0, inplace=True)\n",
    "\n",
    "    return df_perstl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_food_balance[(df_food_balance.element == 'Import Quantity') & (df_food_balance.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_food_balance, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Import Quantity')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_food_balance[(df_food_balance.element == 'Domestic supply quantity') & (df_food_balance.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_food_balance, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Domestic supply quantity')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_food_balance[(df_food_balance.element == 'Protein supply quantity (g/capita/day)') & (df_food_balance.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_food_balance, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Protein supply quantity (g/capita/day)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_food_sicurity[(df_food_sicurity.item == 'Political stability and absence of violence/terrorism (index)') & (df_food_sicurity.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_food_sicurity, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Political stability and absence of violence/terrorism (index)')\n",
    "\n",
    "df_perstl.rename(columns={df_perstl.columns[-1]: 'value_instability'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_food_sicurity[(df_food_sicurity.item == 'Average dietary energy supply adequacy (percent) (3-year average)') & (df_food_sicurity.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_food_sicurity, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Average dietary energy supply adequacy (percent) (3-year average)')\n",
    "\n",
    "df_perstl.rename(columns={df_perstl.columns[-1]: 'value_energy_adeguacy'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(data =df_perstl.sort_values(by='value_instability', ascending=False), x='country', y='value_instability').set( title='Distribution vizualization of instability.')\n",
    "\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values instability is visible only in these few countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value here is value_energy_adeguacy\n",
    "sns.barplot(data =df_perstl.sort_values(by='value_energy_adeguacy', ascending=True), x='country', y='value_energy_adeguacy').set( title='Distribution vizualization of energy adeguancy.')\n",
    "\n",
    "plt.xticks(rotation='vertical', )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On Energy adequacy, we have values for all the countries apart from Burundi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Economical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_macro_indicator[(df_macro_indicator.item ==  'Gross National Income') & (df_macro_indicator.element == 'Value US$') & (df_macro_indicator.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_macro_indicator, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Gross National Income')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_macro_indicator[(df_macro_indicator.item ==  'Gross Domestic Product') & (df_macro_indicator.element == 'Value US$') & (df_macro_indicator.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_macro_indicator, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Gross Domestic Product')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(data =df_perstl.sort_values(by='value_gross_national_income', ascending=True), x='country', y='value_gross_national_income').set( title='Distribution vizualization of gross natiaonal income.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here on value_gross_national_income, we only start to see significant values from DR Congo having china and the USA at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value here is value_gdp_rank\n",
    "sns.barplot(data =df_perstl.sort_values(by='value_gross_domestic_product', ascending=True), x='country', y='value_gross_domestic_product').set( title='Distribution vizualization of gross domestic income product.')\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here value_gross_domestic_product, once again, China and USA are at the top!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Social Cultural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_food_sicurity[(df_food_sicurity.item ==  'Gross domestic product per capita, PPP, dissemination (constant 2011 international $)')  & (df_food_sicurity.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_food_sicurity, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Gross domestic product per capita, PPP, dissemination (constant 2011 international $)')\n",
    "\n",
    "df_perstl.rename(columns={df_perstl.columns[-1]: 'value_ppp_capita'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_food_sicurity[(df_food_sicurity.item ==  'Percentage of population using safely managed sanitation services (Percent)')  & (df_food_sicurity.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_food_sicurity, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Percentage of population using safely managed sanitation services (Percent)')\n",
    "\n",
    "df_perstl.rename(columns={df_perstl.columns[-1]: 'value_sanitation'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(data =df_perstl.sort_values(by='value_ppp_capita', ascending=True), x='country', y='value_ppp_capita', color='green', label='ppp' ).set( title='Distribution vizualization of gross domestic ppp.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At value_ppp_capita, small countries like Burundi have lower capital, and as expected, the USA, China, Germany, France, and Japan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(data =df_perstl.sort_values(by='value_sanitation', ascending=True), x='country', y='value_sanitation', color='lightblue', label= 'sanitation').set( title='Distribution vizualization of sanitation.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Technological"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_food_sicurity[(df_food_sicurity.item ==  'Rail lines density (total route in km per 100 square km of land area)')  & (df_food_sicurity.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_food_sicurity, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Rail lines density (total route in km per 100 square km of land area)')\n",
    "\n",
    "df_perstl.rename(columns={df_perstl.columns[-1]: 'value_automative_railway'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_macro_indicator[(df_macro_indicator.item ==  'Value Added (Manufacture of food, beverages and tobacco products)')  & (df_macro_indicator.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_macro_indicator, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Value Added (Manufacture of food, beverages and tobacco products)')\n",
    "\n",
    "df_perstl.rename(columns={df_perstl.columns[-1]: 'value_manufacture'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(data =df_perstl.sort_values(by='value_automative_railway', ascending=True), x='country', y='value_automative_railway' ).set( title='Distribution vizualization automative railway.')\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value_automative_railway show only values for highly populated countries, which are the USA, Pakistan, India, France, Japan, and Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value here is value_manufacture_rank\n",
    "sns.barplot(data =df_perstl.sort_values(by='value_manufacture', ascending=True), x='country', y='value_manufacture' ).set( title='Distribution vizualization of manufacture.')\n",
    "plt.xticks(rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value_manufacture, this data show only values for Mauritius, Brazil, Russia, and India."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Legal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove  null values by replacing it with mean values.\n",
    "df_perstl = df_perstl.fillna(df_perstl.median())\n",
    "df_perstl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perstl['value_legal_rank'] = df_perstl.value_ppp_capita.rank() + df_perstl.value_automative_railway.rank() + df_perstl.value_manufacture.rank() + df_perstl.value_energy_adeguacy.rank() - df_perstl.value_instability.rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data =df_perstl.sort_values(by='value_legal_rank', ascending=True), x='country', y='value_legal_rank' ).set( title='Distribution vizualization of legal rank.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value_legal_rank is calculated by the sum and difference related to a legal country state. Here we can see countries' values are low, like DR congo to higher than Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected_study = df_macro_indicator[(df_macro_indicator.item ==  'Value Added (Agriculture, Forestry and Fishing)')  & (df_macro_indicator.country.isin(studyCountries))]\n",
    "\n",
    "df_perstl = mergeExtradata(df_to_study= df_macro_indicator, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Value Added (Agriculture, Forestry and Fishing)')\n",
    "\n",
    "df_perstl.rename(columns={df_perstl.columns[-1]: 'value_environmental'}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data =df_perstl.sort_values(by='value_environmental', ascending=True), x='country', y='value_environmental' ).set( title='Distribution vizualization of Environmental.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also here not enough values to be considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perstl = mergeExtradata(df_to_study= df_producer_prices, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Eggs, hen, in shell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data =df_perstl.sort_values(by='value_eggs_hen_in_shell', ascending=True), x='country', y='value_eggs_hen_in_shell' ).set( title='Distribution vizualization of eggs hen in shell.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perstl = mergeExtradata(df_to_study= df_producer_prices, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Eggs Primary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data =df_perstl.sort_values(by='value_eggs_primary', ascending=True), x='country', y='value_eggs_primary' ).set( title='Distribution vizualization of eggs primary.')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perstl = mergeExtradata(df_to_study= df_producer_prices, df_perstl=df_perstl, df_selected_study=df_selected_study, column='Eggs, other bird, in shell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data =df_perstl.sort_values(by='value_eggs_other_bird_in_shell', ascending=True), x='country', y='value_eggs_other_bird_in_shell' ).set( title='Distribution vizualization of eggs other birds in shell')\n",
    "plt.xticks(rotation='vertical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I add more relevant variables to the study data frame eggs values with their countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This then the final PERSTL data set that will then be analyse more with advance algoritims unsupervise machine learning to find more hidden insights on our data set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Statistical test of data distribution.\n",
    "\n",
    "**Testing if the given data belongs to a Gaussian \"Normal\" distribution!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here I am carrying on a statistical test of all Variables created so far.**\n",
    "\n",
    "Had the ALPHA value been defined as 0.05, the hypothesis is \"H0: {Variable} is Normal distribution!\" In the other case, if it is less than the ALPHA value, \"H1: {Variable} is not a Normal distribution!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the Shapiro test function that will create a dictionary and be used to display a data frame of results\n",
    "def normal_shapiro_test( df: DataFrame, column = \"\"):\n",
    "    tested = stats.shapiro(df_perstl[column])\n",
    "    return {\"variable\": column, \"statistic\": tested.statistic, \"pvalue\": tested.pvalue, \n",
    "    \"hypothesis\": \"H0: {} is Normal distribution!\".format(column) if tested.pvalue > 0.05 else \"H1: {} is not a Normal distribution!\".format(column) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(map(lambda c: normal_shapiro_test(df_perstl, c), df_perstl.columns[1:19])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Shapiro shows that most of our variable is not normally distributed, In any case, to continue our analysis, I will perform a normalization or standardization later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimentionality reduction using PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the Reduction of 2 dimensions or using the reduction of components to .95 to have the optimal reduction of all dimensions using PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data and create the scaler variable\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_perstl[df_perstl.columns[1:]])\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the variable to a cluster dataframe.\n",
    "x_clustered = pd.DataFrame(X_scaled, index= df_perstl.index, columns= df_perstl.columns[1:])\n",
    "\n",
    "x_clustered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lets use the anderson_ksamp test to check if value_legal_rank and value_protein_supply_quantity_(g/capita/day) come from a similiar distributions.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if two variables are from a normal distribution.\n",
    "stats.anderson_ksamp([x_clustered.value_legal_rank, x_clustered['value_protein_supply_quantity_(g/capita/day)']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now they both belongs from the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_clustered['value_protein_supply_quantity_(g/capita/day)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the results show here, the p-value is above the alpha, suggesting that the p-value can't reject the H0.\n",
    "\n",
    "The 2 observations might be coming from a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the PCA and the reduced variable**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components = X_scaled.shape[1])\n",
    "pca.fit(X_scaled)\n",
    "x_reducer = pca.transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the number of components created by the PCA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of components created from PCA n_components are 18\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking the ratio of the variance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scree plot, What are the number of component that is relavante to our PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_scree_plot(pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the minimum amount of components that can explain most of our data set, and which one of them are they?\n",
    "\n",
    "This question is a clear answer here in this screed plot. As you can see, with only 1 and 2 components, we can explain more than 50% of our data set.\n",
    "\n",
    "From the PC1-PC11, we can represent almost 99% of the total data set, reducing so 18 PCS to only 5, 10 less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the varioance percentage.\n",
    "round(sum(pca.explained_variance_ratio_[0:11]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the total percentage of the variance of the six components, around 88%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(sum(pca.explained_variance_ratio_[0:5]), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using a bar chart to visualize the amount of PCA explanation of the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df = pd.DataFrame({'var':pca.explained_variance_ratio_,\n",
    "             'PC':['PC' + str(i) for i in range(0, pca.n_components)]})\n",
    "sns.barplot(x='PC',y=\"var\", \n",
    "           data=pc_df, color=\"c\").set( title='variance ration vizualization of PCS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factorial plane of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_circles(pca.components_, pca.n_components, pca, [(0,1)], labels = df_perstl.columns[1:], figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this Circular factorial Map, we can visualize the influence of 2 components 1-2; this component can explain 60,3 percent of the data set in consideration; This is the highest value that can be plotted here according to the preview screed plot.\n",
    "\n",
    "Some variables are influenced by PC1 instead of PC2, like protein supply quantity, population per capita, and value energy adequacy instead of pop total, domestic supply quantity, and import quantity.\n",
    "\n",
    "The direction also of the arrows also gives us a hint about the amount of correlation between these variables. For example, on PC1, most variables, such as energy adequacy and legal value, are highly correlated. Legal and environmental values are slightly less so but still significantly correlated.\n",
    "\n",
    "Another insight to observe here is how the two components are negatively correlated; this is clear by the arrows pointing in the opposite direction, like value population per capita on PC1 and legal rank and instability; this makes sense as legal, and instability in a country can't be the same.\n",
    "\n",
    "The other extra add variables, like eggs primary and eggs other birds in the shell, are influenced by PC1, but PC2 had a strong influence on eggs hen shell; it is also relatively uncorrelated to the other mentioned variables in PC1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A second look to other components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_circles(pca.components_, pca.n_components, pca, [(3,4)], labels = df_perstl.columns[1:], figsize=(15,15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, I plot the circular factorial map with the two least percentage explanation values of our 4,5 components that, as already noticed by the screed plot, can explain a total of 13,9% of this data set.\n",
    "\n",
    "The main insight here is that the less explanatory power these components have, the less correlated their variables are; in fact, more plotted pcs are negatively correlated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Visualizing the calculated 18 components to see how they are clustered.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "display_factorial_planes(x_reducer, pca.n_components, pca, [(0,1)], illustrative_var=df_perstl.columns[1:], alpha=0.8,figsize=(30,15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to be clarified what this plot is showing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Checking the maximum number of clusters that can improve our data from 6 to 12 looks good. After that, there seems not to be significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmeans_tests = [KMeans(n_clusters=i, init='random', n_init=10) for i in range(1, pca.n_components)]\n",
    "score = [kmeans_tests[i].fit(X_scaled).score(X_scaled) for i in range(len(kmeans_tests))]\n",
    "\n",
    "# Plot the curve\n",
    "plt.plot(range(1, pca.n_components_),score)\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating the K-means cluster model, fitting the model, and predicting where the data point is in the cluster.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a k-means clustering model with 4, to 8 clusters\n",
    "kmeans = KMeans(init='random', n_clusters=4, n_init=10)\n",
    "\n",
    "# Fit the data to the model\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Determine which clusters each data point belongs to:\n",
    "clusters =  kmeans.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validating the optimal number of cluster using other metrics\n",
    "\n",
    "**Silhouette Metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the yellowbrick library as it has a better visualization and more information, this take our kmeans model direct with or without number of clusters.\n",
    "visualizer = yellowbrick.SilhouetteVisualizer(kmeans)\n",
    "\n",
    "# Fit data to visualizer\n",
    "visualizer.fit(X_scaled)        \n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At this metric Silhouette, the visualization takes into consideration If there are wider fluctuations on each cluster and if they all stand in the given criteria, the silhouette coefficient values**\n",
    "\n",
    "Four centers or cluster doesn't pass all criteria for an optimal number of the cluster even if relatively closer, but can the Silhouette find a better number than the elbow metric?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_metric_visualizer(n_cluster = [2], metrics = 'silhouette', figsize=(40,120)):\n",
    "   fig, ax = plt.subplots(np.int(len(n_cluster) / 2), 2, figsize=(40,120))\n",
    "   for i in n_cluster:\n",
    "        '''\n",
    "        Create KMeans instance for different number of clusters\n",
    "        '''\n",
    "        km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "        q, mod = divmod(i, 2)\n",
    "        '''\n",
    "        Create SilhouetteVisualizer instance with KMeans instance\n",
    "        Fit the visualizer\n",
    "        '''\n",
    "        \n",
    "        visualizer = yellowbrick.SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "        visualizer.fit(X_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run 14 different numbers of kmean clusters at once**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_metric_visualizer([2,3, 4,5, 6,7, 8,9, 10,11, 12,13, 14,15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**After running the Sihuete** \n",
    "\n",
    "It is clear that the best but not justified number of the cluster could be 4,6 even if it is clear that Silhouette can't give a definitive answer here, so let's use another metric and see if they contradict or show a better number!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Silhouette metrics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using calinski harabasz metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer = yellowbrick.KElbowVisualizer(kmeans, k=(2,18),  metric='calinski_harabasz', timings= True)\n",
    "visualizer.fit(X_scaled)        # Fit data to visualizer\n",
    "visualizer.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The calinski harabasz metric fail**\n",
    "\n",
    "It doesn't give a better number because it contradicts by far the Sihuete and Elbow metric given the optimal number of 2 or 3, so let's revalidate the elbow this time with a noncustom function using the same yellowbrick library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimal cluster number evaluation!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using Elbow metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the yellowbrick library as it has a better visualization and more information, this take our kmeans model direct with or without number of clusters.\n",
    "visualizer = yellowbrick.KElbowVisualizer(kmeans, k=(2,18),  timings= True)\n",
    "visualizer.fit(X_scaled)        # Fit data to visualizer\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen here, we have a model with 6 to 8 clusters; now, let's confirm that 6 clusters are the optimal number by checking all given cluster number averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From all these metrics from 2 to 8, what would be optimal?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the median optimal number of clusters is 4 or 7:\n",
    "\n",
    "opt_num_clusters = int(np.median(np.array([4,2,7])))\n",
    "opt_num_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Summary by taking the mean, we have a number closer to 4,6; this is four, so two is definitely excluded!***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recreating the kmeans with the new optimal cluster number, wich is 6.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a k-means clustering model with 4 clusters\n",
    "kmeans = KMeans(init='random', n_clusters=opt_num_clusters, n_init=10)\n",
    "\n",
    "# Fit the data to the model\n",
    "kmeans.fit(X_scaled)\n",
    "\n",
    "# Determine which clusters each data point belongs to:\n",
    "clusters =  kmeans.predict(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the PCAs Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the centroids reducer\n",
    "centres_reduced = pca.transform(kmeans.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name = list(map(lambda c: 'Cluster_N_' + str(c), clusters))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_factorial_planes(x_reducer, pca.n_components, pca, [(0,1)], illustrative_var = cluster_name, alpha = 0.8, figsize=(20,20))\n",
    "plt.scatter(centres_reduced[:, 0], centres_reduced[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='k', zorder=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What are the countries on each cluster?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perstl['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_clusters = pd.DataFrame(data={'country': df_perstl.country, 'cluster': kmeans.labels_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***The countries cluster***\n",
    "\n",
    "The first and smallest cluster comprises of only India.\n",
    "\n",
    "The largest cluster, number 2, the second has an interesting country like Angola, Brazil, Indonesia, Mexico, Nigeria, Pakistan, and many others.\n",
    "\n",
    "The Third cluster has only China and the United States of America.\n",
    "\n",
    "China Hong Kong SAR, France, Germany, Japan, Russian Federation are in the last cluster, number 4.\n",
    "\n",
    "The mentioned countries could be our recommended countries as many of them have a significant score on the pestle analysis. We can find this out by continuing with hierarchical clustering using a Dendrogram for visualization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_centroids = list(map(lambda n: df_perstl[df_perstl.cluster == n] , range(0, kmeans.n_clusters)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(kmeans.cluster_centers_).to_csv('./P6_Kabuqueci/P6_04_group_centroids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dendrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a hierarch of 4-6 clusters using the ward algorithm as a full tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiercluster = AgglomerativeClustering(affinity='euclidean', linkage='ward', compute_full_tree=True, n_clusters=opt_num_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating prediction cluster using the trained scaler**\n",
    "\n",
    "The number of clusters had been determined by the Kmeans viz, which is the length of centers reduced variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiercluster.set_params(n_clusters= len(centres_reduced))\n",
    "clusters = hiercluster.fit_predict(X_scaled)\n",
    "np.bincount(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a data frame of the scaled with four components to visualize better which features are part of the clusters.**\n",
    "\n",
    "I am visualizing all the variables and influencing the four most important ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the clusters feature distributions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Plotting the data distribution of every cluster on each feature using a box plot so that outliers and min-max values can be visible on each feature*\n",
    "\n",
    "This will also help to see how they influence the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_clustered['cluster'] = clusters\n",
    "\n",
    "x_clustered.boxplot(by='cluster', figsize=(40,20), layout=(5,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster 0 1 and 3 variables like pop trend, value domestic supply, gross domestic product, instability, ppp per capita, protein supply quantity, and value sanitation are higher.\n",
    "\n",
    "What is interesting here is that egg values are all very skew.\n",
    "\n",
    "Also worth mentioning is energy adequacy. So these variables will be taken into consideration for our recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the cluster as a dendrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = linkage(x_clustered, method='ward', metric='euclidean')\n",
    "names = df_perstl.iloc[x_clustered.index].country\n",
    "plot_dendrogram(Z, names.values, figsize=(25, 20), orientation='top')\n",
    "# adding a cut of 5 cluster.\n",
    "plt.axhline(y = 9.7, color = 'magenta', linestyle = '-')\n",
    "\n",
    "plt.tick_params(labelsize='18',labelrotation=90 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much does the dendrogram Explain the kmeans clustering at this point of the Analysis?**\n",
    "\n",
    "We can see that almost all countries clustered are in the same branches, and it is clearer now what variables have more influence on them from the Box plot, viz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dendrogram reflects the influence of the box plot cluster visualization.\n",
    "\n",
    "On the right, we see less stable and legal countries like Indonesia, Gambia, Liberia, etc.\n",
    "\n",
    "There is a clear distinction between countries with higher GDP and PPP per capita here on the right, the top 5 USA, China, Germany, France, and Japan.\n",
    "\n",
    "Apart from Indonesia, all the most populated countries an on the right red and green branches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) A short list (5-10) of potential countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Summary, from the cluster analysis, these are the recommended countries that have been more influenced by the above variable on the cluster and grouped by the dendrogram visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clusters that most influence the PESTLE analysis variables, including import, export, and protein supply quantity, are the countries that can be selected from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The final five countries from clusters 1-2 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the selected countries are in cluster 1-3.\n",
    "selected_data = df_perstl[df_perstl.cluster.isin([0])]\n",
    "selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export cluster county names:\n",
    "pd.DataFrame(selected_data.country).to_csv('./P6_Kabuqueci/P6_03_country_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do they come from the same population?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do they come from the same population?\n",
    "stats.anderson_ksamp([df_perstl[df_perstl.cluster.isin([0])].value_legal_rank, df_perstl[df_perstl.cluster.isin([1])].value_legal_rank])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a0993aee7b2e20d07dcdd6fce1e0f765fc4298a2940963733143d75f620a4776"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
